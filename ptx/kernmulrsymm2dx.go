package ptx

/*
 THIS FILE IS AUTO-GENERATED BY CUDA2GO.
 EDITING IS FUTILE.
*/

import (
	"github.com/barnex/cuda5/cu"
	"sync"
	"unsafe"
)

// pointers passed to CGO must be kept alive manually
// so we keep then here.
// TODO: how about one struct inside the func. will leak not so much and be parallelizeable.
var (
	kernmulRSymm2Dx_lock       sync.Mutex
	kernmulRSymm2Dx_code       cu.Function
	kernmulRSymm2Dx_stream     cu.Stream
	kernmulRSymm2Dx_arg_fftMx  cu.DevicePtr
	kernmulRSymm2Dx_arg_fftKxx cu.DevicePtr
	kernmulRSymm2Dx_arg_N1     int
	kernmulRSymm2Dx_arg_N2     int

	kernmulRSymm2Dx_argptr = [...]unsafe.Pointer{
		unsafe.Pointer(&kernmulRSymm2Dx_arg_fftMx),
		unsafe.Pointer(&kernmulRSymm2Dx_arg_fftKxx),
		unsafe.Pointer(&kernmulRSymm2Dx_arg_N1),
		unsafe.Pointer(&kernmulRSymm2Dx_arg_N2)}
)

// CUDA kernel wrapper for kernmulRSymm2Dx.
// The kernel is launched in a separate stream so that it can be parallel with memcpys etc.
// The stream is synchronized before this call returns.
func K_kernmulRSymm2Dx(fftMx cu.DevicePtr, fftKxx cu.DevicePtr, N1 int, N2 int, gridDim, blockDim cu.Dim3) {
	kernmulRSymm2Dx_lock.Lock()

	if kernmulRSymm2Dx_stream == 0 {
		kernmulRSymm2Dx_stream = cu.StreamCreate()
		//core.Log("Loading PTX code for kernmulRSymm2Dx")
		kernmulRSymm2Dx_code = cu.ModuleLoadData(kernmulRSymm2Dx_ptx).GetFunction("kernmulRSymm2Dx")
	}

	kernmulRSymm2Dx_arg_fftMx = fftMx
	kernmulRSymm2Dx_arg_fftKxx = fftKxx
	kernmulRSymm2Dx_arg_N1 = N1
	kernmulRSymm2Dx_arg_N2 = N2

	args := kernmulRSymm2Dx_argptr[:]
	cu.LaunchKernel(kernmulRSymm2Dx_code, gridDim.X, gridDim.Y, gridDim.Z, blockDim.X, blockDim.Y, blockDim.Z, 0, kernmulRSymm2Dx_stream, args)
	kernmulRSymm2Dx_stream.Synchronize()
	kernmulRSymm2Dx_lock.Unlock()
}

const kernmulRSymm2Dx_ptx = `
.version 3.1
.target sm_30
.address_size 64


.visible .entry kernmulRSymm2Dx(
	.param .u64 kernmulRSymm2Dx_param_0,
	.param .u64 kernmulRSymm2Dx_param_1,
	.param .u32 kernmulRSymm2Dx_param_2,
	.param .u32 kernmulRSymm2Dx_param_3
)
{
	.reg .pred 	%p<5>;
	.reg .s32 	%r<26>;
	.reg .f32 	%f<6>;
	.reg .s64 	%rd<11>;


	ld.param.u64 	%rd3, [kernmulRSymm2Dx_param_0];
	ld.param.u64 	%rd4, [kernmulRSymm2Dx_param_1];
	ld.param.u32 	%r3, [kernmulRSymm2Dx_param_2];
	ld.param.u32 	%r4, [kernmulRSymm2Dx_param_3];
	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	.loc 2 19 1
	mov.u32 	%r5, %ntid.y;
	mov.u32 	%r6, %ctaid.y;
	mov.u32 	%r7, %tid.y;
	mad.lo.s32 	%r1, %r5, %r6, %r7;
	.loc 2 20 1
	mov.u32 	%r8, %ntid.x;
	mov.u32 	%r9, %ctaid.x;
	mov.u32 	%r10, %tid.x;
	mad.lo.s32 	%r2, %r8, %r9, %r10;
	.loc 2 22 1
	setp.ge.s32 	%p1, %r2, %r4;
	setp.ge.s32 	%p2, %r1, %r3;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	BB0_2;

	.loc 2 26 1
	mad.lo.s32 	%r11, %r1, %r4, %r2;
	.loc 2 27 1
	sub.s32 	%r12, %r3, %r1;
	mad.lo.s32 	%r13, %r12, %r4, %r2;
	.loc 2 31 1
	shr.u32 	%r14, %r3, 31;
	add.s32 	%r15, %r3, %r14;
	shr.s32 	%r16, %r15, 1;
	add.s32 	%r17, %r16, 1;
	setp.lt.s32 	%p4, %r1, %r17;
	.loc 2 32 1
	selp.b32 	%r18, %r11, %r13, %p4;
	mul.wide.s32 	%rd5, %r18, 4;
	add.s64 	%rd6, %rd2, %rd5;
	.loc 2 37 1
	shl.b32 	%r19, %r11, 1;
	.loc 2 39 1
	mul.wide.s32 	%rd7, %r19, 4;
	add.s64 	%rd8, %rd1, %rd7;
	.loc 2 40 1
	add.s32 	%r20, %r19, 1;
	mul.wide.s32 	%rd9, %r20, 4;
	add.s64 	%rd10, %rd1, %rd9;
	ld.global.f32 	%f1, [%rd10];
	.loc 2 39 1
	ld.global.f32 	%f2, [%rd8];
	.loc 2 37 1
	ld.global.f32 	%f3, [%rd6];
	.loc 2 42 1
	mul.f32 	%f4, %f2, %f3;
	st.global.f32 	[%rd8], %f4;
	.loc 2 43 1
	mul.f32 	%f5, %f1, %f3;
	st.global.f32 	[%rd10], %f5;

BB0_2:
	.loc 2 44 2
	ret;
}


`
